# Excel Data Cleaner - Complete Application Flow Documentation

## üéØ Overview
`new_streamlit_local.py` is the main entry point for the Excel Data Cleaner application. It orchestrates a multi-stage LLM pipeline for cleaning Excel data using AI.

## üìÅ File Dependencies & Architecture

```
new_streamlit_local.py (Main Application)
‚îÇ
‚îú‚îÄ‚îÄ Configuration & Setup
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # API key management
‚îÇ   ‚îî‚îÄ‚îÄ .env                      # Environment variables (local)
‚îÇ
‚îú‚îÄ‚îÄ Core AI Service Layer
‚îÇ   ‚îî‚îÄ‚îÄ ai_service.py             # Unified AI service with token tracking
‚îÇ       ‚îú‚îÄ‚îÄ AIService class       # Manages Anthropic/OpenAI calls
‚îÇ       ‚îú‚îÄ‚îÄ Token tracking        # Monitors usage & costs
‚îÇ       ‚îî‚îÄ‚îÄ Automatic fallback    # Switches between providers
‚îÇ
‚îú‚îÄ‚îÄ Data Processing Modules
‚îÇ   ‚îú‚îÄ‚îÄ header_detection.py       # AI-powered header detection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AIHeaderDetector      # Identifies & fixes headers
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ cleaning_llm.py          # Cleaning analysis & suggestions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CleaningLLM          # Generates cleaning recommendations
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ code_generator.py        # Code generation for cleaning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CodeGeneratorLLM     # Creates executable Python code
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ data_quality_scorer.py   # Quality assessment
‚îÇ       ‚îú‚îÄ‚îÄ calculate_quality_score()
‚îÇ       ‚îî‚îÄ‚îÄ get_quality_report()
‚îÇ
‚îî‚îÄ‚îÄ Validation & Formatting
    ‚îî‚îÄ‚îÄ format_validators.py      # Format validation
        ‚îî‚îÄ‚îÄ UniversalFormatValidator
```

## üîÑ Complete Application Flow

### Phase 1: Initialization & Setup

```mermaid
Start
  ‚îÇ
  ‚îú‚îÄ> Load environment variables (.env)
  ‚îú‚îÄ> Initialize logging
  ‚îú‚îÄ> Import all modules with fallbacks
  ‚îú‚îÄ> Set Streamlit page config
  ‚îú‚îÄ> Apply custom CSS
  ‚îî‚îÄ> Initialize session state variables
```

**Session State Variables:**
- `uploaded_files_dict` - Stores multiple Excel files
- `selected_file` - Currently selected file
- `selected_sheet` - Currently selected sheet
- `current_df` - Current working dataframe
- `original_df` - Original uploaded dataframe
- `metadata` - Dataset metadata
- `cleaning_suggestions` - LLM-generated suggestions
- `quality_score` - Current quality score
- `quality_report` - Detailed quality report
- `cleaning_history` - History of cleaning operations
- `llm_logs` - LLM activity logs
- `token_usage` - Token tracking (input, output, cost)

### Phase 2: File Upload & Processing (Tab 1)

```
User uploads Excel file(s)
  ‚îÇ
  ‚îú‚îÄ> Store files in session_state.uploaded_files_dict
  ‚îú‚îÄ> Extract sheet names using pd.ExcelFile()
  ‚îî‚îÄ> Display file/sheet selector UI
      ‚îÇ
      ‚îî‚îÄ> User selects file & sheet
          ‚îÇ
          ‚îú‚îÄ> Load selected sheet (pd.read_excel)
          ‚îú‚îÄ> Store original_df
          ‚îÇ
          ‚îú‚îÄ> AI-Enhanced Header Processing
          ‚îÇ   ‚îú‚îÄ> header_detection.AIHeaderDetector()
          ‚îÇ   ‚îú‚îÄ> Makes AI call via ai_service.make_ai_call()
          ‚îÇ   ‚îú‚îÄ> Detects header row
          ‚îÇ   ‚îú‚îÄ> Removes empty rows/columns
          ‚îÇ   ‚îú‚îÄ> Suggests better headers
          ‚îÇ   ‚îî‚îÄ> Returns: processed_df, changes, ai_suggestions
          ‚îÇ
          ‚îú‚îÄ> Initial Quality Assessment
          ‚îÇ   ‚îú‚îÄ> data_quality_scorer.calculate_quality_score()
          ‚îÇ   ‚îú‚îÄ> data_quality_scorer.get_quality_report()
          ‚îÇ   ‚îî‚îÄ> Display initial quality metrics
          ‚îÇ
          ‚îú‚îÄ> Format Validation
          ‚îÇ   ‚îú‚îÄ> format_validators.UniversalFormatValidator()
          ‚îÇ   ‚îú‚îÄ> Validates data formats
          ‚îÇ   ‚îî‚îÄ> Highlights violations
          ‚îÇ
          ‚îî‚îÄ> Generate Metadata
              ‚îú‚îÄ> generate_metadata()
              ‚îú‚îÄ> Identifies data types
              ‚îú‚îÄ> Finds missing values
              ‚îî‚îÄ> Detects quality indicators
```

### Phase 3: Multi-LLM Cleaning Pipeline (Tab 2)

```
User clicks "Run Multi-LLM Cleaning Pipeline"
  ‚îÇ
  ‚îî‚îÄ> run_cleaning_pipeline() [Max 2 iterations, Quality threshold: 50%]
      ‚îÇ
      ‚îú‚îÄ> ITERATION LOOP (max 2 times)
      ‚îÇ   ‚îÇ
      ‚îÇ   ‚îú‚îÄ> Step 1: AI Cleaning Analysis (LLM1)
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> cleaning_llm.CleaningLLM()
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> analyze_and_suggest(df, metadata)
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> Makes AI call for analysis
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> Generates cleaning suggestions
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> Tracks tokens & cost
      ‚îÇ   ‚îÇ   ‚îî‚îÄ> Returns: suggestions list
      ‚îÇ   ‚îÇ
      ‚îÇ   ‚îú‚îÄ> Step 2: Code Generation & Execution (LLM2/3)
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> code_generator.CodeGeneratorLLM()
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> For each suggestion (max 5):
      ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ> generate_code(df, task, context)
      ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ> Makes AI call for code generation
      ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ> Retry logic (3 attempts)
      ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ> Tracks tokens & cost
      ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ> Returns: Python code string
      ‚îÇ   ‚îÇ   ‚îÇ
      ‚îÇ   ‚îÇ   ‚îî‚îÄ> Execute generated code
      ‚îÇ   ‚îÇ       ‚îú‚îÄ> Create safe exec environment
      ‚îÇ   ‚îÇ       ‚îú‚îÄ> Run code with exec()
      ‚îÇ   ‚îÇ       ‚îî‚îÄ> Update dataframe
      ‚îÇ   ‚îÇ
      ‚îÇ   ‚îú‚îÄ> Step 3: Quality Assessment (LLM4)
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> data_quality_scorer.get_quality_report()
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> Calculate new quality score
      ‚îÇ   ‚îÇ   ‚îú‚îÄ> Tracks tokens & cost
      ‚îÇ   ‚îÇ   ‚îî‚îÄ> Display quality metrics
      ‚îÇ   ‚îÇ
      ‚îÇ   ‚îî‚îÄ> Check Quality Threshold
      ‚îÇ       ‚îú‚îÄ> If score >= 50%: Complete
      ‚îÇ       ‚îî‚îÄ> If score < 50% & iterations < 2: Continue loop
      ‚îÇ
      ‚îî‚îÄ> Update session state with final results
```

### Phase 4: Results Review (Tab 3)

```
Display Results
  ‚îÇ
  ‚îú‚îÄ> Show final quality score
  ‚îú‚îÄ> Display cleaned data preview
  ‚îú‚îÄ> Show metadata
  ‚îî‚îÄ> List applied cleaning operations
```

### Phase 5: Download (Tab 4)

```
Download Options
  ‚îÇ
  ‚îú‚îÄ> Display total token usage & cost
  ‚îÇ   ‚îú‚îÄ> Total input tokens
  ‚îÇ   ‚îú‚îÄ> Total output tokens
  ‚îÇ   ‚îî‚îÄ> Total cost in USD
  ‚îÇ
  ‚îú‚îÄ> Excel download (.xlsx)
  ‚îî‚îÄ> CSV download (.csv)
```

## üîå AI Service Integration Flow

```
Any LLM Module makes a call
  ‚îÇ
  ‚îî‚îÄ> ai_service.make_ai_call(prompt, max_tokens, system_prompt)
      ‚îÇ
      ‚îî‚îÄ> AIService.call()
          ‚îÇ
          ‚îú‚îÄ> Try Anthropic (Claude)
          ‚îÇ   ‚îú‚îÄ> _call_anthropic()
          ‚îÇ   ‚îú‚îÄ> Track input/output tokens
          ‚îÇ   ‚îú‚îÄ> Calculate cost ($3/$15 per million)
          ‚îÇ   ‚îî‚îÄ> Return response + token counts
          ‚îÇ
          ‚îú‚îÄ> If fails: Try OpenAI (GPT-4)
          ‚îÇ   ‚îú‚îÄ> _call_openai()
          ‚îÇ   ‚îú‚îÄ> Track input/output tokens
          ‚îÇ   ‚îú‚îÄ> Calculate cost ($30/$60 per million)
          ‚îÇ   ‚îî‚îÄ> Return response + token counts
          ‚îÇ
          ‚îî‚îÄ> Update total token usage & cost
```

## üìä Token Tracking Flow

```
Every AI Call
  ‚îÇ
  ‚îú‚îÄ> Before: Get current token usage
  ‚îú‚îÄ> Make API call
  ‚îú‚îÄ> After: Get new token usage
  ‚îú‚îÄ> Calculate difference
  ‚îú‚îÄ> Update session state
  ‚îî‚îÄ> Display in UI
      ‚îú‚îÄ> Sidebar (running total)
      ‚îú‚îÄ> Activity logs (per operation)
      ‚îî‚îÄ> Final summary (download tab)
```

## üé® UI Components & Display Flow

### Sidebar
- Configuration status
- API key validation
- Token usage & cost (live)
- Cleaning history
- LLM activity logs

### Main Area (4 Tabs)
1. **Upload & Process** - File selection, initial processing
2. **Clean** - Run cleaning pipeline
3. **Results** - Review cleaned data
4. **Download** - Export & cost summary

### Footer
- App info
- Reset token counter button

## üìù Key Functions & Their Roles

### Core Functions in new_streamlit_local.py

1. **init_session_state()**
   - Initializes all session variables
   - Maintains state across reruns

2. **detect_and_process_headers(df)**
   - Calls: `header_detection.AIHeaderDetector()`
   - Returns: processed_df, changes, ai_suggestions

3. **generate_metadata(df)**
   - Analyzes dataframe structure
   - Identifies quality indicators

4. **run_cleaning_pipeline(df, metadata)**
   - Orchestrates multi-LLM cleaning
   - Manages iteration loop
   - Tracks quality improvements

5. **log_llm_activity(activity, llm_name)**
   - Records LLM operations
   - Updates token tracking

6. **display_quality_score(score, report)**
   - Shows quality metrics
   - Displays token usage

## üîß Configuration Files

### .env (Local Configuration)
```
ANTHROPIC_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here  # Optional fallback
```

### requirements.txt
- streamlit
- pandas
- numpy
- anthropic
- openai
- python-dotenv
- openpyxl

## üöÄ Execution Flow Summary

1. **Start**: User runs `streamlit run new_streamlit_local.py`
2. **Initialize**: Load configs, setup UI
3. **Upload**: User uploads Excel file(s)
4. **Select**: Choose file and sheet
5. **Process**: AI header detection, initial cleaning
6. **Clean**: Run multi-LLM pipeline (2 iterations max)
7. **Review**: Check results and quality
8. **Download**: Export cleaned data
9. **Monitor**: Track tokens & cost throughout

## üí° Key Features

- **Multi-file support**: Handle multiple Excel files
- **Multi-sheet support**: Process individual sheets
- **AI-powered cleaning**: 4 different LLMs working together
- **Automatic retries**: Code generation with 3 attempts
- **Quality-driven**: Iterates until quality threshold met
- **Cost tracking**: Real-time token usage & pricing
- **Fallback support**: Automatic switch from Claude to GPT-4
- **Safe execution**: Sandboxed code execution environment

## üîç Error Handling

- Module import fallbacks
- API failure handling
- Code execution safety
- Token tracking resilience
- Session state persistence

## üìà Performance Considerations

- Max 2 cleaning iterations (hardcoded)
- Quality threshold: 50% (hardcoded)
- Top 5 suggestions per iteration
- 3 retry attempts for code generation
- Token usage reset option

This flow ensures efficient, tracked, and cost-effective Excel data cleaning using multiple AI models working in concert.